effects2
ggplot(language_effects, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
ggplot(effects2$`type:language_eq`, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
ggplot(effects2$`type:language_eq`, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
ggplot(effects2$`type:language_eq`, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low__,ymax=upper__),width = 0.1) +geom_point(aes(y=est::),size=4)
ggplot(effects2$`type:language_eq`, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low__,ymax=upper__),width = 0.1) +geom_point(aes(y=est__),size=4)
effects2$`type:language_eq`
ggplot(effects2$`type:language_eq`, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
effects2$`type:language_eq`
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(stat="identity",aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position = position_dodge(),aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position = position_dodge(2),aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq),position = position_dodge(2)) + geom_errorbar(,aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq),position = position_dodge()) + geom_errorbar(,aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq),position = position_dodge()) + geom_errorbar(aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq),position = position_dodge(4)) + geom_errorbar(aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq),position = position_dodge(40)) + geom_errorbar(aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(2),aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(1),aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(1),aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(position= position_dodge(1),aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.1) +geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) +geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4)
ggplot(language_effects, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
modality_effects
ggplot(modality_effects, aes(x=type,color=type)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) +geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4)
effects2$`type:language_eq`
effects2$`type:language_eq` %>% select(type, language_eq,estimate__,lower__,upper__)
ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) +geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4)
effects2$`type:language_eq` %>% select(type, language_eq,estimate__,lower__,upper__)
modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
ggplot(modality_effects, aes(x=type,color=type)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(estimate = mean(estimate__), low=mean(lower__), upper = mean(upper__))
ggplot(modality_effects, aes(x=type,color=type)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
ggplot(modality_effects, aes(x=type,color=type)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=estimate),size=4)
ggplot(modality_effects, aes(x=type,color=type)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.2) +geom_point(aes(y=estimate),size=4)
modality_effects
modality_effects
modality_effects[,7]
modality_effects[7]
modality_effects[1]
modality_effects[1,7]
modality_effects[7,1]
modality_effects[7,]
modality_effects[7,]$estimate
modality_effects$upper
modality_effects %>% mutate(visual_significant = modality_effects[7,]$estimate >modality_effects$upper)
language_effects
effects2$`type:language_eq`
modality_effects
language_effects
language_effects <- effects2$`type:language_eq`  %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__)
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
ggplot(language_effects, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
language_effects
ggplot(language_effects, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
language_effects <- effects2$`type:language_eq`  %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
ggplot(language_effects, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.1) +geom_point(aes(y=est),size=4)
language_effects
language_effects_weighted <- effects2$`type:language_eq` %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
language_effects_weighted
effects2$`type:language_eq`
effects2$`type:language_eq`
install.packages("emmeans")
library(emmeans)
emm_fac1 <- emmean(fit_sc2, ~ type, type = "response")
emmeans(fit_sc2, ~ type, type = "response")
emm_fac1 <- emmeans(fit_sc2, ~ type, type = "response")
fit_sc2
emm_fac1 <- emmeans(fit_sc2, ~ language_eq, type = "response")
emmean(model, ~ factor1, type = "response")
emmean(model, ~ type, type = "response")
emmean(model, ~ "type", type = "response")
emmean(model, type, type = "response")
emmeans(model, ~ factor1, type = "response")
emmeans(fit_sc2, ~ factor1, type = "response")
emmeans(fit_sc2, ~ type, type = "response")
emmeans(fit_sc2, ~ "type", type = "response")
emmeans(fit_sc2, type, type = "response")
emmip(fit_sc2, ~ type, type = "response")
emmip(fit_sc2, ~ type, type = response)
emmeans(fit_sc2, ~ type, type = response)
m_data
m_data %>% select(response, type, language_eq)
emmeans(fit_sc2,~ type, type = "response")
emmeans(fit_sc2,~ language_eq, type = "response")
fit_sc2 %>% emmeans(~ language_eq, type = "response")
new_data %>% group_by(type) %>% summarise(response_count = n())
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
language_effects
emm_int <- emmeans(fit_sc2, ~ language_eq | type, type = "response")
modality_effects
modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(estimate = mean(estimate__), low=mean(lower__), upper = mean(upper__))
ggplot(modality_effects, aes(x=type,color=type)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.2) +geom_point(aes(y=estimate),size=4)
effects2
modality_effects %>% mutate(visual_significant = modality_effects[7,]$estimate >modality_effects$upper)
language_effects
effects2$language_eq
effects2$`type:language_eq`
effects2$`type:language_eq`[FALSE]
effects2$`type:language_eq`[,FALSE]
effects2$`type:language_eq`[FALSE,]
effects2$`type:language_eq` %>% mutate(language_significant = effects2$`type:language_eq`$language_eq)
effects2$`type:language_eq`$estimate__
effects2$`type:language_eq`$estimate__
effects2$`type:language_eq`[0,]$estimate__
effects2$`type:language_eq`[,1]$estimate__
effects2$`type:language_eq`[1,]$estimate__
effects2$`type:language_eq`[FALSE,]$estimate__
effects2$`type:language_eq`
effects2$`type:language_eq`[language_eq ==FALSE,]$estimate__
effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__
effects2$`type:language_eq`
effects2$`type:language_eq` %>% mutate(effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__ < effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == TRUE,]$lower__)
(effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__ < effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == TRUE,]$lower__)
modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(estimate = mean(estimate__), low=mean(lower__), upper = mean(upper__))
modality_effects %>% mutate(language_significants_within_modality = (effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__ < effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == TRUE,]$lower__))
min(m_data$age)
min(m_data$age,na.rm = True)
min(m_data$age,na.rm = T)
max(m_data$age,na.rm = T)
effects2
modality_effects
#check for each modality if estimate of language_eq = False is lower than the lower bound of language_eq = True
modality_effects %>% mutate(language_significants_within_modality = (effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__ < effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == TRUE,]$lower__))
modality_effects
#check for each modality if estimate of language_eq = False is lower than the lower bound of language_eq = True
modality_effects %>% mutate(language_significants_within_modality = (effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__ < effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == TRUE,]$lower__))
#check for each modality if estimate of language_eq = False is lower than the lower bound of language_eq = True
modality_effects %>% mutate(language_significants_within_modality = (effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__ < effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == TRUE,]$lower__))
a
effects2
knitr::opts_chunk$set(echo = TRUE)
#setwd("~/Mental_Imagery_Experiment")
library(tidyverse)
library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)
library(brms)
# install faintr with
#install.packages("HDInterval")
#devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE)
library(faintr)
library(reshape2)
set.seed(123)
# your code here
#data <- read_csv("C:/Users/leado/XP_Lab/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
data %>% glimpse()
#Sven PC1
#data <- read_csv("C:/Users/Groen/Documents/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
# data %>% glimpse()
#Sven PC2
data <- read_csv("C:/Users/SvenG/OneDrive/Sommersemester 2019/Experimental Psychology/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
data %>% glimpse()
#setwd("~/Mental_Imagery_Experiment")
library(tidyverse)
library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)
library(brms)
# install faintr with
#install.packages("HDInterval")
#devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE)
library(faintr)
library(reshape2)
set.seed(123)
#setwd("~/Mental_Imagery_Experiment")
library(tidyverse)
library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)
library(brms)
# install faintr with
#install.packages("HDInterval")
#devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE)
library(faintr)
library(reshape2)
set.seed(123)
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,memessage = FALSE,results = "hold")
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message = FALSE,results = "hold")
# your code here
#data <- read_csv("C:/Users/leado/XP_Lab/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
data %>% glimpse()
#Sven PC1
#data <- read_csv("C:/Users/Groen/Documents/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
# data %>% glimpse()
#Sven PC2
data <- read_csv("C:/Users/SvenG/OneDrive/Sommersemester 2019/Experimental Psychology/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
data %>% glimpse()
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message = FALSE,results = "hold")
fit_sc2
effects2$`type:language_eq`
effects2$`type:language_eq` %>% select(type, language_eq, estimate__,lower__,upper__,se__)
#plotting the data before deleting and after
plot1<- language_effects_plot + ggtitle("using the mean")
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message = FALSE,results = "hold")
#setwd("~/Mental_Imagery_Experiment")
library(tidyverse)
library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)
library(brms)
# install faintr with
#install.packages("HDInterval")
#devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE)
library(faintr)
library(reshape2)
set.seed(123)
# your code here
#data <- read_csv("C:/Users/leado/XP_Lab/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
data %>% glimpse()
#Sven PC1
#data <- read_csv("C:/Users/Groen/Documents/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
# data %>% glimpse()
#Sven PC2
data <- read_csv("C:/Users/SvenG/OneDrive/Sommersemester 2019/Experimental Psychology/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
data %>% glimpse()
#selecting relevant columns
s_data <- select(data, submission_id, trial_name, id, type, response, RT, language, native_language, foreign_language, foreign_dominance, speaking_native, listening_native, writing_native, reading_native, speaking_foreign, listening_foreign, writing_foreign, reading_foreign, reading_time, listening_time, speaking_time, learning_time,age,education, gender,timeSpent) %>% filter(trial_name == "ratingScaleTask")
#here we change the types of the variables
m_data <- mutate(s_data, trial_name = factor(trial_name), type = factor(type), exp_language= language, foreign_dominance = factor(foreign_dominance), subject_id = as.numeric(submission_id), response = factor(response, ordered=TRUE), experiment_id = NULL, language = NULL, submission_id = NULL, id = factor(id),native_language = factor(native_language), foreign_language=factor(foreign_language) , education = factor(education), gender = factor(gender))
#check if the foreign or native language is used in this experiment and add the new column
# if TRUE than the experiment was performend in the native language, else it was performed in the foreign language
m_data <- m_data %>%
mutate(language_eq = (exp_language == native_language))
#filter out the trial tasks as they are irrelevant for us
m_data <- m_data %>% filter(trial_name == "ratingScaleTask")
#Counting number of overall excluded participants
start_participants = nrow(unique(m_data[,"subject_id"]))
start_num_sentences = nrow(m_data)
a = nrow(unique(m_data[,"subject_id"]))
print(paste("Number of Participants before exclusion i: ", a))
#Exclude
new_data <- m_data %>% filter(native_language == "German" | native_language == "English")
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion i: ", b))
print(paste("Excluded: ", a-b))
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion ii: ", a))
#Exclude
new_data <- new_data %>% filter(foreign_language == "German" | foreign_language == "English")
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion ii: ", b))
print(paste("Excluded: ", a-b))
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iii: ", a))
#Exclude
new_data <- new_data %>% filter(foreign_dominance == 'no')
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion iii: ", b))
print(paste("Excluded: ", a-b))
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iV: ",nrow(unique(new_data[,"subject_id"]))))
#transform to string so they can be compared
new_data <- new_data %>%  mutate(native_language = as.character(native_language), foreign_language = as.character(foreign_language))
#Exclude
new_data <- new_data %>% filter(native_language != foreign_language)
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion iV: ", b))
print(paste("Excluded: ", a-b))
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion i: ", a))
# CHECK 95% the same answer
# only check main trials and look at subject id
e_data <- group_by(new_data, subject_id)
e_data <- subset(e_data,select = c(response, subject_id))
# get matrix that shows how often a subject clicked each level of vividness
t1 <- table(e_data)
t1 <- as.data.frame.matrix(t1)
# check if one level was chosen more than 95% (>= 33) and safe index
b <- which(t1 >= 32, arr.ind=T)
# save name of columns that have to be deleted
col_names <-colnames(t1[unique(b[,"col"])])
new_data <- new_data[!(new_data$subject_id %in% col_names),]
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion i: ", b))
print(paste("Excluded: ", a-b))
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion ii: ", a))
# only check main trials and look at subject id
e_data2 <- group_by(new_data, subject_id)
e_data2 <- subset(e_data2,select = c(response, subject_id))
# CHECK IF 5 or more times "i dont know the answer" was chosen
t2 <- table(e_data2)
t2 <- as.data.frame.matrix(t2)
# check given row was chosen more 5 times and safe index
row <- 1
c <- which(t2[row,] >= 5, arr.ind=T)
# save name of columns that have to be deleted
col_names2 <- colnames(t2[unique(c[,"col"])])
new_data <- new_data[!(new_data$subject_id %in% col_names2),]
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion ii: ", b))
print(paste("Excluded: ", a-b))
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iii: ", a))
#get sd and mean
std<-apply(new_data[5], 2, sd)
mean <- apply(new_data[5], 2, mean)
lower_bound = mean-3*std
upper_bound = mean+3*std
std_excl <- new_data %>% mutate(RT_exc_critieria =RT <= lower_bound || RT >= upper_bound)%>% group_by(subject_id) %>% subset(select = c(RT_exc_critieria, subject_id))
t3 <- table(std_excl) %>% as.data.frame.matrix()
# only continue if there are at least one exclusions at all (else the table does not have the TRUE row)
if(nrow(t3 == 2)){
d <- which(t3["TRUE",] >= 5, arr.ind=T)
# save name of columns that have to be deleted
col_names3 <- colnames(t3[unique(d[,"col"])])
#exclude
new_data <- new_data[!(new_data$subject_id %in% col_names3),]
}
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion iii: ", b))
print(paste("Excluded: ", a-b))
a = nrow(new_data)
new_data <- new_data %>% filter(response != 0)
b = a - nrow(new_data)
print(paste("number of excluded sentences: ", b))
# Count how many participants have been excluded:
num_excluded = nrow(unique(m_data[,"subject_id"]))-nrow(unique(new_data[,"subject_id"]))
print(paste("Started with ", start_participants, " participants"))
print(paste("Overall Number of excluded participants: ", num_excluded))
print(paste("Remaining number of Participants: ", start_participants - num_excluded))
exc_sentences = start_num_sentences - nrow(new_data)
print(paste("Started with ", start_num_sentences, " sentences"))
print(paste("Overall number of removed sentences", exc_sentences))
print(paste("Remaining number of sentences", nrow(new_data)))
d_individual_summary <- new_data  %>% group_by(subject_id) %>%  summarize(mean_RT = mean(RT), timeSpent=mean(timeSpent), writing_foreign = mean(writing_foreign), speaking_foreign= mean(speaking_foreign), listening_foreign = mean(listening_foreign), writing_native = mean(writing_native), speaking_native = mean(speaking_native),listening_native = mean(listening_native),reading_time = mean(reading_time), listening_time= mean(listening_time), speaking_time = mean(speaking_time), learning_time=mean(learning_time), age = mean(age), education = unique(education),gender = unique(gender), exp_language = unique(exp_language), native_language = unique(native_language), foreign_language= unique(foreign_language), language_eq = (exp_language == native_language))
#gender was presented in German and English
#this translates the german version into english
d_individual_summary$gender <- ifelse(d_individual_summary$gender == "männlich" & d_individual_summary$gender != "male" & d_individual_summary$gender != "female", "male","female")
#same with education:
for (i in 1:nrow(d_individual_summary)){
if(!is.na(d_individual_summary[i,"education"]) & d_individual_summary[i,"education"] == "anderes")
{d_individual_summary[i,"education"] = "other"}
if(!is.na(d_individual_summary[i,"education"]) & d_individual_summary[i,"education"] == "Abitur")
{d_individual_summary[i,"education"] = "Graduated High School (Abitur)"}
if(!is.na(d_individual_summary[i,"education"]) & d_individual_summary[i,"education"] == "Hochschulabschluss (Bachelor/Master)")
{d_individual_summary[i,"education"] = "Graduated College"}
if(!is.na(d_individual_summary[i,"education"]) & d_individual_summary[i,"education"] == "Höherer Abschluss")
{d_individual_summary[i,"education"] = "Higher Degree"}
}
d_individual_summary
d_individual_summary %>% ggplot(aes(x=gender)) + theme_bw() + geom_bar()
d_individual_summary %>% group_by(gender) %>% summarise(gender_count = n())
d_individual_summary %>% ggplot(aes(x=education, fill = gender)) + theme_bw() + geom_bar() +  scale_x_discrete(labels=c("Grad. College", "Grad. High School", "Higher Degree", "other","NA"))
d_individual_summary %>% group_by(education) %>% summarise(education_count = n())
#Barplot
ggplot(d_individual_summary, aes(x=age, fill=gender)) + theme_bw() + geom_bar()
age_mean <- d_individual_summary[ , c("age")] %>% na.omit() %>% apply(2, FUN = mean)
age_median <- d_individual_summary[ , c("age")] %>% na.omit() %>% apply(2, FUN = median)
print(paste("The average age of our participants is: ",
age_mean, "years"))
print(paste("and the media age of our participants is: ",
age_median))
comm <- setNames(data.frame(matrix(ncol = 6, nrow = 0)), c("comments", "submission_id", "education", "native_language", "foreign_language", "foreign_dominance"))
for (i in 1:nrow(data)){
if (!is.na(data[i,"comments"])){
new_row <- data.frame("comments" = data[i,"comments"], "submission_id" = data[i,"submission_id"], "education" = data[i,"education"], "native_language" = data[i,"native_language"], "foreign_language" = data[i,"foreign_language"], "foreign_dominance" = data[i,"foreign_dominance"])
comm <- rbind(comm, new_row) %>% unique()
}
}
comm
d_individual_summary %>%  group_by(native_language) %>% summarise(language_exp_count = n())
d_individual_summary %>%  group_by(language_eq) %>% summarise(language_eq_count = n())
language_summary <- (colMeans( m_data[ , c("writing_foreign", "speaking_foreign", "listening_foreign","reading_foreign", "writing_native", "listening_native","speaking_native","reading_native")],na.rm = TRUE)) %>% as.matrix()
colnames(language_summary) <- c("rating")
tmp<- melt(language_summary)
names(tmp) = c("language_skill", "", "value")
ggplot(tmp, aes(x=language_skill,y=value)) +
geom_bar(stat="identity", position="dodge", colour="black")  +
theme_bw()
print("The subjective language Ratings: ")
print(language_summary)
objective_language <- d_individual_summary %>% gather(key=variable, value = value, c("reading_time","listening_time", "speaking_time", "learning_time"))
objective_language_count <- objective_language %>% group_by(variable) %>% summarise(mean_answer = mean(value))
objective_language_count
objective_language_count %>% ggplot() + geom_bar(mapping = aes(x=variable,y =mean_answer),stat = "identity") + theme_bw()
#brms model creation
fit_sc1 <- brm(
formula = response ~ type*language_eq,
data = new_data,
family = cumulative("logit")
)
fit_sc2 <- brm(
formula = response ~ type * language_eq  + (1|subject_id),
data = new_data,
family = cumulative("logit")
)
(loo(fit_sc1,fit_sc2))
fit_sc2
effects2 <- marginal_effects(fit_sc2)
effects2
analyse_data <- new_data %>% mutate(response = as.integer(response))
analyse_data %>% group_by(language_eq) %>% summarise(mean_response=mean(response), median_response = median((response)))
effects2$`type:language_eq` %>% select(type, language_eq, estimate__,lower__,upper__,se__)
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
language_effects_plot<-ggplot(language_effects, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.3) +geom_point(aes(y=est),size=4)
language_effects_plot
language_effects
new_data %>% group_by(type) %>% summarise(response_count = n())
new_data %>% group_by(type) %>% ggplot(aes(x=type)) + geom_bar()
modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(estimate = mean(estimate__), low=mean(lower__), upper = mean(upper__))
#check for each modality if estimate of language_eq = False is lower than the lower bound of language_eq = True
modality_effects<-modality_effects %>% mutate(language_significants_within_modality = (effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__ < effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == TRUE,]$lower__))
#Plotting for visualisation
modality_language_plot <-ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) +geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4)
modality_language_plot
modality_effects
analyse_data %>% group_by(type) %>% summarise(mean_response = mean(response))
effects2$`type:language_eq` %>% select(type, language_eq,estimate__,lower__,upper__)
modality_language_plot
modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(estimate = mean(estimate__), low=mean(lower__), upper = mean(upper__))
modality_plot <- ggplot(modality_effects, aes(x=type,color=type)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.2) +geom_point(aes(y=estimate),size=4)
modality_effects
modality_plot
modality_effects %>% mutate(visual_significant = modality_effects[7,]$estimate >modality_effects$upper)
modality_language_plot
modality_plot
modality_effects %>%  mutate(gustatory_significant_lower = modality_effects[2,]$estimate < modality_effects$low,olfactory_significant_lower = modality_effects[4,]$estimate < modality_effects$low)
fit_sc3  <- brm(
formula = response ~ language_eq + (1|subject_id),
data = new_data,
family = cumulative("logit")
)
'fit_sc2 <- brm(
formula = response ~ type * language_eq  + (1|subject_id),
data = new_data,
family = cumulative("logit")
)
and
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))'
effects3 <- marginal_effects(fit_sc3)
language_effects2 <- effects3$language_eq %>%  select(language_eq,estimate__,lower__,upper__)
#compute the difference for each cell
result <- language_effects2[,2:4] - language_effects[,2:4]
result
fit_sc4  <- brm(
formula = response ~ type + (1|subject_id),
data = new_data,
family = cumulative("logit")
)
'fit_sc2 <- brm(
formula = response ~ type * language_eq  + (1|subject_id),
data = new_data,
family = cumulative("logit")
)
and
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))'
effects4 <- marginal_effects(fit_sc4)
effects4
modality_effects2 <- effects4$type %>%  select(type,estimate__,lower__,upper__)
modality_effects
#compute the difference for each cell
result2 <- modality_effects2[,2:4] - modality_effects[,2:4]
result2
#plotting the data before deleting and after
plot1<- language_effects_plot + ggtitle("using the mean")
plot2<-ggplot(language_effects2, aes(x=language_eq,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) + geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4) + ggtitle("using a model with 1 dependent variable")
plot3<- modality_plot + ggtitle("using the mean")
plot4<- ggplot(modality_effects2, aes(x=type ,color=type)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) + geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4) + ggtitle("using a model with 1 dependent variable")
require(gridExtra)
grid.arrange(plot1,plot2,ncol=2)
grid.arrange(plot3,plot4,ncol=2)
#grid.arrange(plot1,plot2,plot3,plot4,ncol=2,nrow=2)
#transform since the wilcox function requires numeric input
new_data_manu <- new_data %>% mutate(response=as.integer(response))
#testing
manu_language<-wilcox.test(new_data_manu$response ~ new_data_manu$language_eq)
manu_language
#collecting 20 random subject_id's
d_individual_summary %>% group_by(exp_language) %>%  summarise(count = n())
tmp <- new_data %>% filter(exp_language == "German")
index <- tmp$subject_id
index <- sample(unique(index),20)
#randomly delete 20:
equal_data <- new_data[!(new_data$subject_id %in% index),]
equal_data %>% group_by(exp_language) %>%  summarise(count = n())
#check if equal number of german and english
after_individual_summary <- group_by(equal_data,subject_id) %>%  summarise(exp_language = unique(exp_language))
after_individual_summary %>% group_by(exp_language) %>% summarise(count=n())
#run new model
fit_sc5 <-brm(
formula = response ~ type*language_eq   + (1|subject_id),
data = equal_data,
family = cumulative("logit")
)
effects5 <- marginal_effects(fit_sc5)
#get data
after_rndm_delete <- effects5$`type:language_eq` %>% select(type,language_eq,estimate__,lower__,upper__)
before_rndm_delete <- effects2$`type:language_eq` %>% select(type,language_eq,estimate__,lower__,upper__)
#calculate difference
difference <- before_rndm_delete[,3:5] - after_rndm_delete[,3:5]
#plotting the data before deleting and after
plot1<-ggplot(before_rndm_delete, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) + geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4)+ ggtitle("before random deleting")
plot2<-ggplot(after_rndm_delete, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) + geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4) + ggtitle("after random deleting")
require(gridExtra)
grid.arrange(plot1,plot2,ncol=2)
difference
