---
title: "Mental_Imagery_analysis"
output: html_document
---

```{r}
#setwd("~/Mental_Imagery_Experiment")
library(tidyverse)

library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)

library(brms)

# install faintr with 
#install.packages("HDInterval")
#devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE)
library(faintr)


set.seed(123)

```



```{r}
# your code here
data <- read_csv("C:/Users/Groen/Documents/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz (1).csv")
data %>% glimpse()


```


```{r}
# + native_language = languages, + the language test results
(s_data <- select(data, submission_id, trial_name, id, type, response, RT, language, native_language, foreign_language, foreign_dominance, speaking_native, listening_native, writing_native, speaking_foreign, listening_foreign, writing_foreign, reading_time, listening_time, speaking_time, learning_time))

```



```{r}
#here we change the types of the variables
m_data <- mutate(s_data, trial_name = factor(trial_name), type = factor(type), exp_language= language, foreign_dominance = factor(foreign_dominance), subject_id = as.numeric(submission_id), response = factor(response, ordered=TRUE), experiment_id = NULL, language = NULL, submission_id = NULL)

m_data
```


```{r}
#here we calculate the mean for the different types of the real task
#(s_data2 <- group_by(m_data, type) %>% filter(trial_name=="ratingScaleTask") %>% summarise(type_mean=mean(response)))
```


```{r}
#check if the foreign or native language is used in this experiment and add the new column
m_data <- m_data %>% 
  mutate(language_eq = (exp_language == native_language))
```

#Exclusion Criteria:
```{r}
#Counting number of overall excluded participants
start_participants = nrow(unique(m_data[,"subject_id"]))

```

## Specific Criteria:

### Criteria i:
If a participant has chosen the exact same rating in 95% or more of the 35 stimuli (≥ 95% of the same rate), then this participant is going to be excluded from the analysis

```{r}
print(paste("Number of Participants before exclusion i: ",nrow(unique(m_data[,"subject_id"]))))

# CHECK 95% the same answer
# only check main trials and look at subject id
e_data <- group_by(m_data, subject_id) %>% filter(trial_name == "ratingScaleTask")
e_data <- subset(e_data,select = c(response, subject_id))

# get matrix that shows how often a subject clicked each level of vividness
t1 <- table(e_data)
t1 <- as.data.frame.matrix(t1)



# check if one level was chosen more than 95% (>= 33) and safe index
b <- which(t1 >= 32, arr.ind=T)
# save name of columns that have to be deleted
col_names <-colnames(t1[unique(b[,"col"])])

new_data <- m_data[!(m_data$subject_id %in% col_names),]

print(paste("Number of Participants before exclusion i: ", nrow(unique(new_data[,"subject_id"]))))


```

### Criteria ii:
If a participant has chosen the option “I don’t understand the sentence” 5 times or more (≥ 5x “I don’t understand”), then this participant is going to be excluded from the analysis


```{r}
print(paste("Number of Participants before exclusion ii: ",nrow(unique(new_data[,"subject_id"]))))
# CHECK IF 5 or more times "i dont know the answer" was chosen
t2 <- table(e_data2) 
t2 <- as.data.frame.matrix(t2)

# check given row was chosen more 5 times and safe index
row <- 1
c <- which(t2[row,] >= 5, arr.ind=T)
# save name of columns that have to be deleted

col_names2 <- colnames(t2[unique(c[,"col"])])
new_data <- new_data[!(new_data$subject_id %in% col_names2),]
print(paste("Number of Participants before exclusion ii: ", nrow(unique(new_data[,"subject_id"]))))


```

### criteria iii:
We are going to look at the overall distribution of data and exclude every trial of a participant that deviates three standard deviations above and below the mean with respect to the participants' reaction time. If for one participant there are five trials or more where the reaction time deviates three standard deviations above and below the mean reaction time, the whole participant is going to be excluded from the analysis. We will also check how the analysis differs with and without these participants.

```{r}
std<-apply(new_data[5], 2, sd)
mean <- apply(new_data[5], 2, mean)
lower_bound = mean-3*std
upper_bound = mean+3*std

std_excl <- new_data %>% mutate(RT_exc_critieria =RT <= lower_bound || RT >= upper_bound)%>% group_by(subject_id) %>% filter(trial_name == "ratingScaleTask") %>% subset(select = c(RT_exc_critieria, subject_id))


###################PROBLEM##########
#hier fehlt uns im daten eine stelle wo das "TRUE" sein müsste...daher hat die table nur eine spalte 
#daher füg ich ein "Fake" TRUE hinzu um unten zu testen
#test
std_excl[nrow(std_excl) + 1,]= list(TRUE,999)
##

t3[2,] #funktioniert
t3[TRUE,] #funktioniert nicht (WARUM?!?)

# only continue if there are at least one exclusions at all (else the table does not have the TRUE row)
if(nrow(t3 != 2)){
  d <- which(t3[,TRUE] >= 5, arr.ind=T)
  col_names3 <- colnames(t3[unique(d[,"col"])])
  #exclude
  print(col_names3)
  #new_data <- new_data[!(new_data$subject_id %in% col_names3),]
}





```



## Results of Exclusion

```{r}
# Count how many participants have been excluded:
num_excluded = nrow(unique(m_data[,"subject_id"]))-nrow(unique(new_data[,"subject_id"]))
print(paste("Started with ", start_participants, " participants"))
print(paste("Overall Number of excluded participants: ", num_excluded))
print(paste("Remaining number of Participants: ", start_participants - num_excluded))

```


```{r}
#filter the data for our prerequisites
#write down precise exclusion criteria here
m_data <- filter(m_data, foreign_dominance == 'no', foreign_language == 'English'| foreign_language == 'German', native_language == 'English'| native_language == 'German') %>% subset(response !=0, foreign_language!=native_language)
m_data
```



```{r}
#here we calculate the mean for the different types of the real task and group by language equality (set foreign_language == native_language)
#(s_data3 <- group_by(m_data, type, language_eq) %>% filter(trial_name=="ratingScaleTask") %>% summarise(type_lang_mean=mean(response)))

```


```{r}
#brms model creation 

fit_sc1 <- brm(
formula = response ~ language_eq + type,
data = m_data,
family = cumulative("logit")
)

```
```{r}
fit_sc1
```
```{r}
fit_sc2 <- brm(
formula = response ~ language_eq + type + (1|subject_id),
data = m_data,
family = cumulative("logit")
)
```


```{r}
(loo(fit_sc1,fit_sc2))
```

```{r}
post_samples <- posterior_samples(fit_sc2) %>% 
  as_tibble()
```

```{r}
effects <- marginal_effects(fit_sc2)
effects$language_eq
effects$type
```

