---
title: "Mental_Imagery_analysis"
output: html_document
---

```{r}
library(tidyverse)

library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)

library(brms)

# install faintr with 
#install.packages("HDInterval")
#devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE)
library(faintr)


set.seed(123)

```



```{r}
# your code here
(data <- read_csv("C:/Users/leado/XP_Lab/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz (1).csv"))
data %>% glimpse()


```


```{r}
# + native_language = languages, + the language test results
(s_data <- select(data, submission_id, trial_name, id, type, response, RT, language, native_language, foreign_language, foreign_dominance, speaking_native, listening_native, writing_native, speaking_foreign, listening_foreign, writing_foreign, reading_time, listening_time, speaking_time, learning_time))

```



```{r}
#here we change the types of the variables
m_data <- mutate(s_data, trial_name = factor(trial_name), type = factor(type), exp_language= language, foreign_dominance = factor(foreign_dominance), subject_id = as.numeric(submission_id), response = factor(response, ordered=TRUE), experiment_id = NULL, language = NULL, submission_id = NULL)

m_data
```


```{r}
#here we calculate the mean for the different types of the real task
#(s_data2 <- group_by(m_data, type) %>% filter(trial_name=="ratingScaleTask") %>% summarise(type_mean=mean(response)))
```
```{r}
#check if the foreign or native language is used in this experiment and add the new column
m_data <- m_data %>% 
  mutate(language_eq = (exp_language == native_language))
```

```{r}
#add exclusion criteria
e_data <- group_by(m_data, subject_id) %>% filter(trial_name == "ratingScaleTask")
e_data <- subset(e_data,select = c(response, subject_id))

#CHECK 95% the same answer
# get matrix that shows how often a subject clicked each level of vividness
a <- table(e_data) %>% as.data.frame.matrix(a)

# check if one level was chosen more than 95% (>= 33) and safe index
b <- which(a >= 32, arr.ind=T)
# save name of columns that have to be deleted
col_names <-colnames(a[unique(b[,"col"])])

new_data <- m_data[!(m_data$subject_id %in% col_names),]

# CHECK IF 5 or more time "i dont know the answer was choosen
row <-3
c <- which(a[row,] >= 5, arr.ind=T)
#print(a[3,])
c
```




```{r}
#filter the data for our prerequisites
#write down precise exclusion criteria here
m_data <- filter(m_data, foreign_dominance == 'no', foreign_language == 'English'| foreign_language == 'German', native_language == 'English'| native_language == 'German') %>% subset(response !=0, foreign_language!=native_language)
m_data
```



```{r}
#here we calculate the mean for the different types of the real task and group by language equality (set foreign_language == native_language)
#(s_data3 <- group_by(m_data, type, language_eq) %>% filter(trial_name=="ratingScaleTask") %>% summarise(type_lang_mean=mean(response)))

```


```{r}
#brms model creation 

fit_sc1 <- brm(
formula = response ~ language_eq + type,
data = m_data,
family = cumulative("logit")
)

```
```{r}
fit_sc1
```
```{r}
fit_sc2 <- brm(
formula = response ~ language_eq + type + (1|subject_id),
data = m_data,
family = cumulative("logit")
)
```


```{r}
(loo(fit_sc1,fit_sc2))
```

```{r}
post_samples <- posterior_samples(fit_sc2) %>% 
  as_tibble()
```

```{r}
effects <- marginal_effects(fit_sc2)
effects$language_eq
effects$type
```

