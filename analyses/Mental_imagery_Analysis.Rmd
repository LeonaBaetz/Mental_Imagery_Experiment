---
title: "Mental_Imagery_analysis"
output:
  html_document: default
  pdf_document: default
  word_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message = FALSE,results = "hold")
```

# Analysis
## Preparing the Data
### Librarys used

```{r}
#setwd("~/Mental_Imagery_Experiment")
library(tidyverse)

library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)

library(brms)

# install faintr with 
#install.packages("HDInterval")
#devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE)
library(faintr)
library(reshape2)


set.seed(123)

```

### Reading data

```{r}
# your code here

#data <- read_csv("C:/Users/leado/XP_Lab/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
data %>% glimpse()

#Sven PC1
#data <- read_csv("C:/Users/Groen/Documents/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
# data %>% glimpse()

#Sven PC2
data <- read_csv("C:/Users/SvenG/OneDrive/Sommersemester 2019/Experimental Psychology/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")

data %>% glimpse()

```
### Preparing for Analysis

```{r}
#selecting relevant columns
s_data <- select(data, submission_id, trial_name, id, type, response, RT, language, native_language, foreign_language, foreign_dominance, speaking_native, listening_native, writing_native, reading_native, speaking_foreign, listening_foreign, writing_foreign, reading_foreign, reading_time, listening_time, speaking_time, learning_time,age,education, gender,timeSpent) %>% filter(trial_name == "ratingScaleTask")

#here we change the types of the variables
m_data <- mutate(s_data, trial_name = factor(trial_name), type = factor(type), exp_language= language, foreign_dominance = factor(foreign_dominance), subject_id = as.numeric(submission_id), response = factor(response, ordered=TRUE), experiment_id = NULL, language = NULL, submission_id = NULL, id = factor(id),native_language = factor(native_language), foreign_language=factor(foreign_language) , education = factor(education), gender = factor(gender))


#check if the foreign or native language is used in this experiment and add the new column
# if TRUE than the experiment was performend in the native language, else it was performed in the foreign language
m_data <- m_data %>% 
  mutate(language_eq = (exp_language == native_language))

#filter out the trial tasks as they are irrelevant for us
m_data <- m_data %>% filter(trial_name == "ratingScaleTask")

```

## Exclusion Criteria:
```{r}
#Counting number of overall excluded participants
start_participants = nrow(unique(m_data[,"subject_id"]))
start_num_sentences = nrow(m_data)
```
### a. Excluding Criteria regarding the participants:

#### Criteria i:
Participants having neither English nor German as native language are going to be excluded from the analysis
```{r}
a = nrow(unique(m_data[,"subject_id"]))
print(paste("Number of Participants before exclusion i: ", a))

#Exclude
new_data <- m_data %>% filter(native_language == "German" | native_language == "English")

b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion i: ", b))
print(paste("Excluded: ", a-b))

```

#### Criteria ii:
Participants having neither English nor German as a foreign language are going to be excluded from the analysis
```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion ii: ", a))


#Exclude
new_data <- new_data %>% filter(foreign_language == "German" | foreign_language == "English")

b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion ii: ", b))
print(paste("Excluded: ", a-b))

```

#### Criteria iii:
Participants where their foreign language is their dominant language are going to be excluded: Participants that have spoken their foreign language in their homes and/or if they are speaking in their foreign language more often (in their daily life) than their actual native language are going to be excluded from the analysis
```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iii: ", a))


#Exclude
new_data <- new_data %>% filter(foreign_dominance == 'no')

b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion iii: ", b))
print(paste("Excluded: ", a-b))
```

#### Criteria iv:
Exclude any participant which native language is equal to their foreign language
```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iV: ",nrow(unique(new_data[,"subject_id"]))))

#transform to string so they can be compared
new_data <- new_data %>%  mutate(native_language = as.character(native_language), foreign_language = as.character(foreign_language))

#Exclude
new_data <- new_data %>% filter(native_language != foreign_language)

b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion iV: ", b))
print(paste("Excluded: ", a-b))
```


### Specific Criteria:

#### Criteria i:
If a participant has chosen the exact same rating in 95% or more of the 35 stimuli (≥ 95% of the same rate), then this participant is going to be excluded from the analysis

```{r}

a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion i: ", a))


# CHECK 95% the same answer
# only check main trials and look at subject id
e_data <- group_by(new_data, subject_id)
e_data <- subset(e_data,select = c(response, subject_id))

# get matrix that shows how often a subject clicked each level of vividness
t1 <- table(e_data)
t1 <- as.data.frame.matrix(t1)



# check if one level was chosen more than 95% (>= 33) and safe index
b <- which(t1 >= 32, arr.ind=T)
# save name of columns that have to be deleted
col_names <-colnames(t1[unique(b[,"col"])])

new_data <- new_data[!(new_data$subject_id %in% col_names),]

b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion i: ", b))
print(paste("Excluded: ", a-b))

```

#### Criteria ii:
If a participant has chosen the option “I don’t understand the sentence” 5 times or more (≥ 5x “I don’t understand”), then this participant is going to be excluded from the analysis

```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion ii: ", a))

# only check main trials and look at subject id
e_data2 <- group_by(new_data, subject_id)
e_data2 <- subset(e_data2,select = c(response, subject_id))

# CHECK IF 5 or more times "i dont know the answer" was chosen
t2 <- table(e_data2) 
t2 <- as.data.frame.matrix(t2)

# check given row was chosen more 5 times and safe index
row <- 1
c <- which(t2[row,] >= 5, arr.ind=T)
# save name of columns that have to be deleted

col_names2 <- colnames(t2[unique(c[,"col"])])
new_data <- new_data[!(new_data$subject_id %in% col_names2),]

b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion ii: ", b))
print(paste("Excluded: ", a-b))

```

#### Criteria iii:
We are going to look at the overall distribution of data and exclude every trial of a participant that deviates three standard deviations above and below the mean with respect to the participants' reaction time. If for one participant there are five trials or more where the reaction time deviates three standard deviations above and below the mean reaction time, the whole participant is going to be excluded from the analysis. We will also check how the analysis differs with and without these participants.

```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iii: ", a))

#get sd and mean
std<-apply(new_data[5], 2, sd)
mean <- apply(new_data[5], 2, mean)
lower_bound = mean-3*std
upper_bound = mean+3*std

std_excl <- new_data %>% mutate(RT_exc_critieria =RT <= lower_bound || RT >= upper_bound)%>% group_by(subject_id) %>% subset(select = c(RT_exc_critieria, subject_id))


t3 <- table(std_excl) %>% as.data.frame.matrix()


# only continue if there are at least one exclusions at all (else the table does not have the TRUE row)
if(nrow(t3 == 2)){
  d <- which(t3["TRUE",] >= 5, arr.ind=T)
  # save name of columns that have to be deleted
  col_names3 <- colnames(t3[unique(d[,"col"])])
  #exclude
  new_data <- new_data[!(new_data$subject_id %in% col_names3),]
}

b= nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants after exclusion iii: ", b))
print(paste("Excluded: ", a-b))
```

#### Criteria iv:
Any sentence that received the response “I don’t understand the sentence” is useless for our purpose of analysis, thus for each participant that was not excluded via ii. but made use of this choice, the respective sentence(s) are excluded from the participants analysis, however the remaining ones are used.

```{r}
a = nrow(new_data)
new_data <- new_data %>% filter(response != 0) %>%  mutate(response=factor(response,levels = c(1,2,3,4,5,6,7)))

b = a - nrow(new_data)

print(paste("number of excluded sentences: ", b))

```


### Results of Exclusion:

```{r}
# Count how many participants have been excluded:
num_excluded = nrow(unique(m_data[,"subject_id"]))-nrow(unique(new_data[,"subject_id"]))
print(paste("Started with ", start_participants, " participants"))
print(paste("Overall Number of excluded participants: ", num_excluded))
print(paste("Remaining number of Participants: ", start_participants - num_excluded))
exc_sentences = start_num_sentences - nrow(new_data)
print(paste("Started with ", start_num_sentences, " sentences"))
print(paste("Overall number of removed sentences", exc_sentences))
print(paste("Remaining number of sentences", nrow(new_data)))
```


## Getting an Overview of the Data

### Looking at the data for each participant
```{r}
d_individual_summary <- new_data  %>% group_by(subject_id) %>% mutate(response=as.integer(response)) %>% summarize(mean_RT = mean(RT), timeSpent=mean(timeSpent), writing_foreign = mean(writing_foreign), speaking_foreign= mean(speaking_foreign), listening_foreign = mean(listening_foreign), writing_native = mean(writing_native), speaking_native = mean(speaking_native),listening_native = mean(listening_native),reading_time = mean(reading_time), listening_time= mean(listening_time), speaking_time = mean(speaking_time), learning_time=mean(learning_time), age = mean(age), education = unique(education),gender = unique(gender), exp_language = unique(exp_language), native_language = unique(native_language), foreign_language= unique(foreign_language), language_eq = (exp_language == native_language),response=mean(response))

#gender was presented in German and English
#this translates the german version into english
d_individual_summary$gender <- ifelse(d_individual_summary$gender == "männlich" & d_individual_summary$gender != "male" & d_individual_summary$gender != "female", "male","female")

#same with education:
for (i in 1:nrow(d_individual_summary)){
  
  if(!is.na(d_individual_summary[i,"education"]) & d_individual_summary[i,"education"] == "anderes")
  {d_individual_summary[i,"education"] = "other"}
  if(!is.na(d_individual_summary[i,"education"]) & d_individual_summary[i,"education"] == "Abitur")
  {d_individual_summary[i,"education"] = "Graduated High School (Abitur)"}
  if(!is.na(d_individual_summary[i,"education"]) & d_individual_summary[i,"education"] == "Hochschulabschluss (Bachelor/Master)")
  {d_individual_summary[i,"education"] = "Graduated College"}
  if(!is.na(d_individual_summary[i,"education"]) & d_individual_summary[i,"education"] == "Höherer Abschluss")
  {d_individual_summary[i,"education"] = "Higher Degree"}
}
d_individual_summary
```

### Gender distribution

```{r}
d_individual_summary %>% ggplot(aes(x=gender)) + theme_bw() + geom_bar()
d_individual_summary %>% group_by(gender) %>% summarise(gender_count = n())
```

### Education Distribution

```{r}
d_individual_summary %>% ggplot(aes(x=education, fill = gender)) + theme_bw() + geom_bar() +  scale_x_discrete(labels=c("Grad. College", "Grad. High School", "Higher Degree", "other","NA"))
d_individual_summary %>% group_by(education) %>% summarise(education_count = n())
```


### Age Distribution

```{r}
#Barplot
ggplot(d_individual_summary, aes(x=age, fill=gender)) + theme_bw() + geom_bar() 

age_mean <- d_individual_summary[ , c("age")] %>% na.omit() %>% apply(2, FUN = mean)
age_median <- d_individual_summary[ , c("age")] %>% na.omit() %>% apply(2, FUN = median)


print(paste("The average age of our participants is: ", 
age_mean, "years"))
print(paste("and the media age of our participants is: ", 
age_median))

```
One can see that the majority of our participants is around 22 years old.

### Participants' Comments

```{r}
comm <- setNames(data.frame(matrix(ncol = 6, nrow = 0)), c("comments", "submission_id", "education", "native_language", "foreign_language", "foreign_dominance"))

for (i in 1:nrow(data)){
  if (!is.na(data[i,"comments"])){
    new_row <- data.frame("comments" = data[i,"comments"], "submission_id" = data[i,"submission_id"], "education" = data[i,"education"], "native_language" = data[i,"native_language"], "foreign_language" = data[i,"foreign_language"], "foreign_dominance" = data[i,"foreign_dominance"])
    
    comm <- rbind(comm, new_row) %>% unique()
  }
}

comm

```

### Language Levels

```{r}

d_individual_summary %>%  group_by(native_language) %>% summarise(language_exp_count = n())
d_individual_summary %>%  group_by(language_eq) %>% summarise(language_eq_count = n())
```
We have only German native speaking participants. 27 participants performed the experiment in their foreign language (english) and 47 performed the experiment in their native language (47)

#### Subjective Language Proficiency
```{r}
language_summary <- (colMeans( m_data[ , c("writing_foreign", "speaking_foreign", "listening_foreign","reading_foreign", "writing_native", "listening_native","speaking_native","reading_native")],na.rm = TRUE)) %>% as.matrix()
colnames(language_summary) <- c("rating")


tmp<- melt(language_summary)
names(tmp) = c("language_skill", "", "value")


ggplot(tmp, aes(x=language_skill,y=value)) +
  geom_bar(stat="identity", position="dodge", colour="black")  +
  theme_bw()

print("The subjective language Ratings: ")
print(language_summary)
```
keys to the numbers:
0 = "not at all proficient",
1 = "very little proficient",
2 = "little proficient",
3 = "average proficient",
4 = "good proficient",
5 = "very good proficient",
6 = "totally proficient".


#### "Objective" language Proficiency

```{r}
objective_language <- d_individual_summary %>% gather(key=variable, value = value, c("reading_time","listening_time", "speaking_time", "learning_time"))  
objective_language_count <- objective_language %>% group_by(variable) %>% summarise(mean_answer = mean(value))
objective_language_count
objective_language_count %>% ggplot() + geom_bar(mapping = aes(x=variable,y =mean_answer),stat = "identity") + theme_bw()
```
For Learning time:

(1: 0-2 years, 2: 2-5 years, 3:  5-7 years, 4:  7-10 years, 5: 10-15 years, 6: more than 15 years)

For Reading/Listening/Speaking time:

(1: 0-4 hours/month, 2:  1-2 hours/week, 3:  3-5 hours/week, 4: 6-10 hours/week, 5: more than 10 hours/week)

# Bayesian Regression
## Creating and comparing models

```{r}
#brms model creation 

fit_sc1 <- brm(
formula = response ~ type*language_eq,
data = new_data,
family = cumulative("logit")
)

```


```{r}
fit_sc2 <- brm(
formula = response ~ type * language_eq  + (1|subject_id),
data = new_data,
family = cumulative("logit")
)
```


```{r}
(loo(fit_sc1,fit_sc2))
```

In the model comparisons we see fit_sc2 with elpd_diff and se_diff of 0.Therefore, we will continue our analysis with fit_sc2 


```{r}
fit_sc2
```

```{r}
effects2 <- marginal_effects(fit_sc2)
effects2
```


## Testing the hypothesis

Remember: "language_eq" = TRUE means the participant performed the Experiment in their native language

### Main hypothesis:

#### H1:
We hypothesize that using a foreign language reduces the vividness of mental imagery or simulations compared to the vividness of mental imagery or stimulation evoked by the usage of the native language:
H1: On average the overall-ratings for "vividness" in the condition "foreign language" are smaller than in the condition "native language".


##### First look at the average responses:
```{r}
analyse_data <- new_data %>% mutate(response = as.integer(response))
analyse_data %>% group_by(language_eq) %>% summarise(mean_response=mean(response), median_response = median((response)))
```

##### testing for significance
We are not sure on how to deal with this hypothesis, since our model shows us the interaction of language with each modality (effects2$`type:language_eq):

```{r}
effects2$`type:language_eq` %>% select(type, language_eq, estimate__,lower__,upper__,se__)
```
This shows us the overall possible combinations of each modality with either native or foreign language and their respective estimate, lower bound and upper bound. We will use this table for later hypothesis extensively. For H1 however, we need to know if the difference of language_eq=False and language_eq=True is significant over all hypothesis.


Our Hypothesis can be translated to:
On average the overall-ratings for "vividness" in the condition language_eq=False are smaller than in the condition language_eq=True.
To see if this hold we look at the average (mean) values over all modalities:
```{r}
language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))
language_effects_plot<-ggplot(language_effects, aes(x=language_eq,color=language_eq)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.3) +geom_point(aes(y=est),size=4)
language_effects_plot
language_effects

```

One can see that for language_eq=False the estimate 5.171 is barely withing the boundaries of language_eq=True (low=5.170 and upper=5.67).
This would indicate that the difference in vividness for native and foreign language is not significant.

We doupt the accuracy of the result for the following reason:

##### The (probable) problem of using the mean:
In "Specific Criterion"->"Criteria iv" we excluded every sentence that received the answer "I don't know the answer" because this sentence does not include any information about vividness of the mental image the participant had, simply because he/she didn't understood the question. This results in the fact that the amount of answer for each modality we received is different of each modality!

```{r}
new_data %>% group_by(type) %>% summarise(response_count = n())
new_data %>% group_by(type) %>% ggplot(aes(x=type)) + geom_bar()
```


The amount of answered sentences for each modality varies. Therefore, we think it might be problematic to just use the mean() function to calculate the overall estimate + lower and upper bound. 

#### H2:
Furthermore we hypothesize, that the vividness of mental imagery or simulation of a (sensory) experience differs across different modalities between the two types of language:
H2: On average the modality-specific-ratings for "vividness" in the condition "foreign language" are smaller (less vivid) than in the condition "native language" (more vivid).


Here compare if the estimate of each modality for the condition language_eq=False is within the boundaries of language_eq=True of the same modality.
```{r}

modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(estimate = mean(estimate__), low=mean(lower__), upper = mean(upper__))

#check for each modality if estimate of language_eq = False is lower than the lower bound of language_eq = True
modality_effects<-modality_effects %>% mutate(language_significants_within_modality = (effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == FALSE,]$estimate__ < effects2$`type:language_eq`[effects2$`type:language_eq`$language_eq == TRUE,]$lower__))

#Plotting for visualisation
modality_language_plot <-ggplot(effects2$`type:language_eq`, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) +geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4)

modality_language_plot
modality_effects
```

One can see that this holds only for gustatory, organic and tactile. We conclude that H2 is false. It does hold for some, but not for all modalities!

### Hypothesis of relationships between variables:

#### H3:
Moreover, we suggest that sensory experiences are easier (more vividly) to simulate for some modalities compared to other modalities. 
H3: More specific, we hypothesize that mental images evoked by visual simulations have higher vividness-ratings than those evoked by the other six modalities


When only looking at the mean response of the different modalities one can see that the visual response rating is not the highest.
```{r}
analyse_data %>% group_by(type) %>% summarise(mean_response = mean(response))
```


If one looks at the output plot of the marginal effects2$type:language_eq:

```{r}
effects2$`type:language_eq` %>% select(type, language_eq,estimate__,lower__,upper__)
modality_language_plot
```

it seems obvious that H3 is false. One can see clearly that the rating of vividness for "visual" is not significantly higher than all the other modalities.
It is significantly higher than olfactory for both native and foreign language and significantly higher than gustatory for foreign laguage but not native language.

If we assume, like in H1, that using the mean is a correct way to average over the language_eq we get the following result:

```{r}
modality_effects <- effects2$`type:language_eq` %>% group_by(type) %>% summarise(estimate = mean(estimate__), low=mean(lower__), upper = mean(upper__))
modality_plot <- ggplot(modality_effects, aes(x=type,color=type)) + geom_errorbar(aes(ymin=low,ymax=upper),width = 0.2) +geom_point(aes(y=estimate),size=4)
modality_effects
modality_plot
```

This result indicates that H3 is wrong since the estimate for type=visual is not significantly larger than the upper bound of all other modalities:

```{r}
modality_effects %>% mutate(visual_significant = modality_effects[7,]$estimate >modality_effects$upper)
```

However it would also classify visual as significantly higher as gustatory. So the result is similiar to the one using effects2$`type:language_eq`.


#### H4:

We also think that sensory experiences are harder (less vividly) imagined for some modalities compared to other modalities. 
H4: Here we think that mental simulations evoked by the olfactory or gustatory modality have lower vividness-ratings than those evoked by the other five modalities

```{r}
modality_language_plot
```

This hypothesis states that the olfactory estimate and gustatory ratings are significantly lower than the other modalities. In the given graph one can see that this does only hold for olfactory when also considering the language type. Within language_eq = Flase (orange) the olfactory ratings are significantly smaller than the other modalities (exepct gustatory). For language_eq = true (native) it is significantly smaller compared to all modalities. 
```{r}
modality_plot
modality_effects %>%  mutate(gustatory_significant_lower = modality_effects[2,]$estimate < modality_effects$low,olfactory_significant_lower = modality_effects[4,]$estimate < modality_effects$low)
```

If we compare this to the modality_plot that uses the mean to average over the language we can see a different result. The olfactory rating is significantly smaller than all other modalities in the modeality plot.

In the case of gustatory, it is significantly lower than auditory, motor, organic and also visual (which was only the case for foreign language in modality_language_plot)

We can say that H4 is partly true, since olfactory got a significantly lower vividness rating compared to the rest of the modalities. This however does not hold for the gustatory modality.


## Further remarks

### Trying alternative Methods/Models 
As H1 stated, we are interested of the influence on vividness when using a foreign language. Above we used a brm model that showed us the interaction of type and language_eq (fit_sc2). In order to get the information about language_eq without the influence of the modality types, we average over the modalities. We are not sure whether this is methodological correct.

#### foreign vs. native Language
Below we use a brm model that completly ignores the type of modalities. We want to know whether the results would be similiar to the ones from fit_sc2 and averaging 

```{r}
fit_sc3  <- brm(
formula = response ~ language_eq + (1|subject_id),
data = new_data,
family = cumulative("logit")
)

'fit_sc2 <- brm(
formula = response ~ type * language_eq  + (1|subject_id),
data = new_data,
family = cumulative("logit")
)

and 

language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))'

effects3 <- marginal_effects(fit_sc3)
language_effects2 <- effects3$language_eq %>%  select(language_eq,estimate__,lower__,upper__)

#compute the difference for each cell
result <- language_effects2[,2:4] - language_effects[,2:4]
result
```
One can see that the difference is very small! So using the mean() to create langauge_effects seems to be a way to approximate language_effects2.
We are, however, not sure if this is still the correct model to test for significance.


#### Modality comparison
Below, we try out the same like above to see if the same observation can be made for the modalities.

```{r}
fit_sc4  <- brm(
formula = response ~ type + (1|subject_id),
data = new_data,
family = cumulative("logit")
)

'fit_sc2 <- brm(
formula = response ~ type * language_eq  + (1|subject_id),
data = new_data,
family = cumulative("logit")
)

and 

language_effects <- effects2$`type:language_eq` %>% group_by(language_eq) %>% summarise(est = mean(estimate__), low=mean(lower__), upper = mean(upper__))'

effects4 <- marginal_effects(fit_sc4)
effects4
modality_effects2 <- effects4$type %>%  select(type,estimate__,lower__,upper__)

modality_effects
#compute the difference for each cell
result2 <- modality_effects2[,2:4] - modality_effects[,2:4]
result2

```

Like above, the difference is very small. fit_sc4 seems to approximate fit_sc2 with averaging over the language

#### Visualising both

```{r}
#plotting the data before deleting and after
plot1<- language_effects_plot + ggtitle("using the mean")

plot2<-ggplot(language_effects2, aes(x=language_eq,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) + geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4) + ggtitle("using a model with language as dependent variable")

plot3<- modality_plot + ggtitle("using the mean")

plot4<- ggplot(modality_effects2, aes(x=type ,color=type)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) + geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4) + ggtitle("using a model with type as dependent variable")
 
  

require(gridExtra)
grid.arrange(plot1,plot2,ncol=2)
grid.arrange(plot3,plot4,ncol=2)
#grid.arrange(plot1,plot2,plot3,plot4,ncol=2,nrow=2)

```

#### Mann-Whitney-U test

In the original experiment the authors used a U-test to test for significance. Hence, below we tried if using a U test would show similiar results:

```{r}
#transform since the wilcox function requires numeric input

new_data_manu <- d_individual_summary %>%  select(response,language_eq)
new_data_manu

#testing
manu_language<-wilcox.test(new_data_manu$response ~ new_data_manu$language_eq, conf.level=0.95)
manu_language
n1=27
n2=47
U=452

# we need to calculate the z value because our n is larger than 20
z=(U-(n1*n2)/2)/sqrt((n1*n2*(n1+n2+1))/12)
z
abs(z)>1.96
```
The result of the Mann-Whitney-U test indicates a significant difference between foreign and native language. alpha = 0.05, p = `r manu_language$p.value`.


#### ANOVA

```{r}
new_data_anova <- new_data %>% select(response,type) 
new_data_anova <- new_data_anova[order(new_data_anova$type),] %>% mutate(response=as.integer(response))



boxplot(new_data_anova$response~new_data_anova$type)
summary(aov(data= new_data_anova, formula = response~type))

```
The result suggest that there is a significant difference between the different modalities.

##### Determine between which groups the difference is significant

```{r}
post_hoc<-TukeyHSD(aov(data= new_data_anova, formula = response~type))
post_hoc
```
the result suggest that there is not significant difference for:

- motor-auditory
- organic-auditory
- tactile-gustatory
- visual-gustatory
- organic-motor
- visual-tactile

```{r}
modality_plot
```
Our data Suggest not a significant difference for:

- auditory - motor 
- auditory - organic
- gustatory - tactile
- gustatory - visual
- motor - organic
- tactile - visual


The results are exactly the same. We are not sure however, if the anova package was used correctly and do not want to make any statement about it.


### Restricting the participants

Our distribution of participants who did the experiment in their nativ vs foreign language is not equal. Below we delete randomly 20 participants who did the experiment in German and see if our model changes.

```{r}
#collecting 20 random subject_id's
d_individual_summary %>% group_by(exp_language) %>%  summarise(count = n())
tmp <- new_data %>% filter(exp_language == "German")
index <- tmp$subject_id
index <- sample(unique(index),20)

#randomly delete 20:
equal_data <- new_data[!(new_data$subject_id %in% index),]

#check if equal number of german and english
after_individual_summary <- group_by(equal_data,subject_id) %>%  summarise(exp_language = unique(exp_language))
after_individual_summary %>% group_by(exp_language) %>% summarise(count=n())

#run new model
fit_sc5 <-brm(
formula = response ~ type*language_eq   + (1|subject_id),
data = equal_data,
family = cumulative("logit")
)
effects5 <- marginal_effects(fit_sc5)

#get data
after_rndm_delete <- effects5$`type:language_eq` %>% select(type,language_eq,estimate__,lower__,upper__)
before_rndm_delete <- effects2$`type:language_eq` %>% select(type,language_eq,estimate__,lower__,upper__)

#calculate difference
difference <- before_rndm_delete[,3:5] - after_rndm_delete[,3:5]

#plotting the data before deleting and after
plot1<-ggplot(before_rndm_delete, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) + geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4)+ ggtitle("before random deleting")

plot2<-ggplot(after_rndm_delete, aes(x=type,color=language_eq)) + geom_errorbar(position= position_dodge(0.5),aes(ymin=lower__,ymax=upper__),width = 0.3) + geom_point(position= position_dodge(0.5),aes(y=estimate__),size=4) + ggtitle("after random deleting")

require(gridExtra)
grid.arrange(plot1,plot2,ncol=2)
difference
```

The difference is very small! There are differences but we do not consider them meaningfull. 
