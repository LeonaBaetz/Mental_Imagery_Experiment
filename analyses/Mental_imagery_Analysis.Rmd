---
title: "Mental_Imagery_analysis"
output: html_document
---

```{r}
#setwd("~/Mental_Imagery_Experiment")
library(tidyverse)

library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)

library(brms)

# install faintr with 
#install.packages("HDInterval")
#devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE)
library(faintr)


set.seed(123)

```



```{r}
# your code here
data <- read_csv("C:/Users/Groen/Documents/Mental_Imagery_Experiment/data/results_72_Mental_Imagery_Experiment_Sveana+Spellbanovicz.csv")
data %>% glimpse()

data
```


```{r}
# + native_language = languages, + the language test results
(s_data <- select(data, submission_id, trial_name, id, type, response, RT, language, native_language, foreign_language, foreign_dominance, speaking_native, listening_native, writing_native, speaking_foreign, listening_foreign, writing_foreign, reading_time, listening_time, speaking_time, learning_time))

```



```{r}
#here we change the types of the variables
m_data <- mutate(s_data, trial_name = factor(trial_name), type = factor(type), exp_language= language, foreign_dominance = factor(foreign_dominance), subject_id = as.numeric(submission_id), response = factor(response, ordered=TRUE), experiment_id = NULL, language = NULL, submission_id = NULL)

```


```{r}
#here we calculate the mean for the different types of the real task
#(s_data2 <- group_by(m_data, type) %>% filter(trial_name=="ratingScaleTask") %>% summarise(type_mean=mean(response)))
```


```{r}
#check if the foreign or native language is used in this experiment and add the new column
m_data <- m_data %>% 
  mutate(language_eq = (exp_language == native_language))

#filter out the trial tasks as they are irrelevant for us
m_data <- m_data %>% filter(trial_name == "ratingScaleTask")

```

#Exclusion Criteria:
```{r}
#Counting number of overall excluded participants
start_participants = nrow(unique(m_data[,"subject_id"]))
start_num_sentences = nrow(m_data)

```
## a. Excluding Criteria regarding the participants:

### Criteria i:
Participants having neither English nor German as native language are going to be excluded from the analysis
```{r}
a = nrow(unique(m_data[,"subject_id"]))
print(paste("Number of Participants before exclusion i: ",nrow(unique(m_data[,"subject_id"]))))

#Exclude
new_data <- m_data %>% filter(native_language == "German" | native_language == "English")


print(paste("Number of Participants after exclusion i: ", nrow(unique(new_data[,"subject_id"]))))
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Excluded: ", a-b))

```

### Criteria ii:
Participants having neither English nor German as a foreign language are going to be excluded from the analysis
```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion ii: ",nrow(unique(new_data[,"subject_id"]))))


#Exclude
new_data <- new_data %>% filter(foreign_language == "German" | foreign_language == "English")


print(paste("Number of Participants after exclusion i: ", nrow(unique(new_data[,"subject_id"]))))
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Excluded: ", a-b))

```


### Criteria iii:
Participants where their foreign language is their dominant language are going to be excluded: Participants that have spoken their foreign language in their homes and/or if they are speaking in their foreign language more often (in their daily life) than their actual native language are going to be excluded from the analysis
```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iii: ",nrow(unique(new_data[,"subject_id"]))))


#Exclude
new_data <- new_data %>% filter(foreign_dominance == 'no')

print(paste("Number of Participants after exclusion iii: ", nrow(unique(new_data[,"subject_id"]))))
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Excluded: ", a-b))
```

### Criteria iv:
Exclude any participant which native language is equal to their foreign language
```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iV: ",nrow(unique(new_data[,"subject_id"]))))



#Exclude
new_data <- new_data %>% filter(native_language != foreign_language)

print(paste("Number of Participants after exclusion iV: ", nrow(unique(new_data[,"subject_id"]))))
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Excluded: ", a-b))
```



## Specific Criteria:

### Criteria i:
If a participant has chosen the exact same rating in 95% or more of the 35 stimuli (≥ 95% of the same rate), then this participant is going to be excluded from the analysis

```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion i: ",nrow(unique(new_data[,"subject_id"]))))

# CHECK 95% the same answer
# only check main trials and look at subject id
e_data <- group_by(new_data, subject_id)
e_data <- subset(e_data,select = c(response, subject_id))

# get matrix that shows how often a subject clicked each level of vividness
t1 <- table(e_data)
t1 <- as.data.frame.matrix(t1)



# check if one level was chosen more than 95% (>= 33) and safe index
b <- which(t1 >= 32, arr.ind=T)
# save name of columns that have to be deleted
col_names <-colnames(t1[unique(b[,"col"])])

new_data <- new_data[!(new_data$subject_id %in% col_names),]

print(paste("Number of Participants after exclusion i: ", nrow(unique(new_data[,"subject_id"]))))
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Excluded: ", a-b))


```

### Criteria ii:
If a participant has chosen the option “I don’t understand the sentence” 5 times or more (≥ 5x “I don’t understand”), then this participant is going to be excluded from the analysis


```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion ii: ",nrow(unique(new_data[,"subject_id"]))))


# CHECK IF 5 or more times "i dont know the answer" was chosen
t2 <- table(e_data2) 
t2 <- as.data.frame.matrix(t2)

# check given row was chosen more 5 times and safe index
row <- 1
c <- which(t2[row,] >= 5, arr.ind=T)
# save name of columns that have to be deleted

col_names2 <- colnames(t2[unique(c[,"col"])])
new_data <- new_data[!(new_data$subject_id %in% col_names2),]

print(paste("Number of Participants after exclusion ii: ", nrow(unique(new_data[,"subject_id"]))))
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Excluded: ", a-b))

```

### criteria iii:
We are going to look at the overall distribution of data and exclude every trial of a participant that deviates three standard deviations above and below the mean with respect to the participants' reaction time. If for one participant there are five trials or more where the reaction time deviates three standard deviations above and below the mean reaction time, the whole participant is going to be excluded from the analysis. We will also check how the analysis differs with and without these participants.

```{r}
a = nrow(unique(new_data[,"subject_id"]))
print(paste("Number of Participants before exclusion iii: ",nrow(unique(new_data[,"subject_id"]))))

#get sd and mean
std<-apply(new_data[5], 2, sd)
mean <- apply(new_data[5], 2, mean)
lower_bound = mean-3*std
upper_bound = mean+3*std

std_excl <- new_data %>% mutate(RT_exc_critieria =RT <= lower_bound || RT >= upper_bound)%>% group_by(subject_id) %>% subset(select = c(RT_exc_critieria, subject_id))


t3 <- table(std_excl) %>% as.data.frame.matrix()

# only continue if there are at least one exclusions at all (else the table does not have the TRUE row)
if(nrow(t3 == 2)){
  d <- which(t3["TRUE",] >= 5, arr.ind=T)
  # save name of columns that have to be deleted
  col_names3 <- colnames(t3[unique(d[,"col"])])
  #exclude
  new_data <- new_data[!(new_data$subject_id %in% col_names3),]
}

print(paste("Number of Participants after exclusion iii: ", nrow(unique(new_data[,"subject_id"]))))
b= nrow(unique(new_data[,"subject_id"]))
print(paste("Excluded: ", a-b))
```


### criteria iv:
Any sentence that received the response “I don’t understand the sentence” is useless for our purpose of analysis, thus for each participant that was not excluded via ii. but made use of this choice, the respective sentence(s) are excluded from the participants analysis, however the remaining ones are used.

```{r}
a = nrow(new_data)
new_data <- new_data %>% filter(response != 0)
b = a - nrow(new_data)

print(paste("number of excluded sentences: ", b))

```


## Results of Exclusion

```{r}
# Count how many participants have been excluded:
num_excluded = nrow(unique(m_data[,"subject_id"]))-nrow(unique(new_data[,"subject_id"]))
print(paste("Started with ", start_participants, " participants"))
print(paste("Overall Number of excluded participants: ", num_excluded))
print(paste("Remaining number of Participants: ", start_participants - num_excluded))
exc_sentences = start_num_sentences - nrow(new_data)
print(paste("Started with ", start_num_sentences, " sentences"))
print(paste("Overall number of removed sentences", exc_sentences))
print(paste("Remaining number of sentences", nrow(new_data)))

```


```{r}
#filter the data for our prerequisites
#write down precise exclusion criteria here
#m_data <- filter(m_data, foreign_dominance == 'no', foreign_language == 'English'| foreign_language == 'German', native_language == 'English'| native_language == 'German') %>% subset(response !=0, foreign_language!=native_language)
#m_data
```



```{r}
#here we calculate the mean for the different types of the real task and group by language equality (set foreign_language == native_language)
#(s_data3 <- group_by(m_data, type, language_eq) %>% filter(trial_name=="ratingScaleTask") %>% summarise(type_lang_mean=mean(response)))

```


```{r}
#brms model creation 

fit_sc1 <- brm(
formula = response ~ language_eq + type,
data = m_data,
family = cumulative("logit")
)

```


```{r}
fit_sc1
```
```{r}
fit_sc2 <- brm(
formula = response ~ language_eq + type + (1|subject_id),
data = m_data,
family = cumulative("logit")
)
```


```{r}
(loo(fit_sc1,fit_sc2))
```

```{r}
post_samples <- posterior_samples(fit_sc2) %>% 
  as_tibble()
```

```{r}
effects <- marginal_effects(fit_sc2)
effects$language_eq
effects$type
```

